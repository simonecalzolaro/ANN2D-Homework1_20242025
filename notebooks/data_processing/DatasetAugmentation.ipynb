{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NagH2Pkyj_A2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/[2024-2025]AN2DL/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqnIzWHEk7Fn"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "#from tensorflow import keras as tfk\n",
        "import keras as tfk       #notice how I'm importing keras and not tensorflow.keras\n",
        "from keras.layers import Input, Dense, Dropout, Lambda\n",
        "#from tensorflow.keras.layers import Input, Dense, Dropout, Lambda\n",
        "from keras import layers as tfkl\n",
        "\n",
        "\n",
        "print(f\"Tensorflow version -> {tf.__version__}\")\n",
        "print(f\"Keras version -> {tfk.__version__}\")\n",
        "# Set seed for TensorFlow\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "# Reduce TensorFlow verbosity\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# Print TensorFlow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Import other libraries\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Configure plot display settings\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFgokZTokog6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "data = np.load('training_set_cleaned.npz')\n",
        "\n",
        "# Code for exploring npz content\n",
        "print(data.files)\n",
        "for key in data.files:\n",
        "    array = data[key]\n",
        "    print(f\"Array '{key}':\")\n",
        "    print(f\"  Shape: {array.shape}\")\n",
        "    print(f\"  Data Type: {array.dtype}\")\n",
        "\n",
        "#arrays\n",
        "X = data['images']\n",
        "y = data['labels']\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "# Define a mapping of labels to their corresponding cell type names\n",
        "labels = {\n",
        "    0: 'Basophil',\n",
        "    1: 'Eosinophil',\n",
        "    2: 'Erythroblast',\n",
        "    3: 'Immature granulocytes',\n",
        "    4: 'Lymphocyte',\n",
        "    5: 'Monocyte',\n",
        "    6: 'Neutrophil',\n",
        "    7: 'Platelet'\n",
        "}\n",
        "# Save unique labels\n",
        "unique_labels = list(labels.values())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_kmDTqDmaW9C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOZVNG4NkrO2"
      },
      "outputs": [],
      "source": [
        "# Split data into training and validation sets, maintaining class distribution\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.1,\n",
        "    random_state=seed,\n",
        "    stratify=y\n",
        ")\n",
        "# Print the shapes of the resulting datasets\n",
        "print(\"Training Data Shape:\", X_train.shape)\n",
        "print(\"Training Label Shape:\", y_train.shape)\n",
        "print(\"Validation Data Shape:\", X_val.shape)\n",
        "print(\"Validation Label Shape:\", y_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rFUuaKgkv3X"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def display_random_samples(X, y, grid_size=(10, 10), title=\"Random Samples\"):\n",
        "    \"\"\"\n",
        "    Displays random samples from the dataset in a grid.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy array): Array of images (num_samples, height, width, channels).\n",
        "        y (numpy array): Corresponding labels (num_samples,).\n",
        "        grid_size (tuple): Grid dimensions (rows, cols). Default is (10, 10).\n",
        "        title (str): Title for the entire grid.\n",
        "    \"\"\"\n",
        "    rows, cols = grid_size\n",
        "    num_samples = rows * cols\n",
        "\n",
        "    # Randomly select indices for the samples\n",
        "    random_indices = np.random.choice(X.shape[0], num_samples, replace=False)\n",
        "    selected_images = X[random_indices]\n",
        "    selected_labels = y[random_indices]\n",
        "\n",
        "    # Create the plot\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # Display the image\n",
        "        ax.imshow(selected_images[i].astype('uint8'))\n",
        "        ax.set_title(f\"Label: {selected_labels[i]}\")\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.92)  # Adjust space for the title\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "# Assuming X_train and y_train are NumPy arrays\n",
        "# X_train: (num_samples, height, width, channels)\n",
        "# y_train: (num_samples,)\n",
        "display_random_samples(X_train, y_train, grid_size=(10, 10), title=\"Random Training Samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhNNsDNkk2k4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "labels = {\n",
        "    0: 'Basophil',\n",
        "    1: 'Eosinophil',\n",
        "    2: 'Erythroblast',\n",
        "    3: 'Immature granulocytes',\n",
        "    4: 'Lymphocyte',\n",
        "    5: 'Monocyte',\n",
        "    6: 'Neutrophil',\n",
        "    7: 'Platelet'\n",
        "}\n",
        "# Save unique labels\n",
        "unique_labels = list(labels.values())\n",
        "\n",
        "def show_class_distribution(X, y, labels_dict=None):\n",
        "    \"\"\"\n",
        "    Displays the class distribution in the dataset.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy array): Array of images (num_samples, height, width, channels).\n",
        "        y (numpy array): Array of labels (num_samples,).\n",
        "        labels_dict (dict, optional): Mapping of class indices to class names. Default is None.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Count occurrences of each class\n",
        "    class_counts = Counter(y.flatten())\n",
        "    classes = list(class_counts.keys())\n",
        "    counts = list(class_counts.values())\n",
        "\n",
        "    # Sort classes for better visualization\n",
        "    sorted_indices = np.argsort(classes)\n",
        "    sorted_classes = np.array(classes)[sorted_indices]\n",
        "    sorted_counts = np.array(counts)[sorted_indices]\n",
        "\n",
        "    # Display as a table\n",
        "    print(\"Class Distribution:\")\n",
        "    print(\"-------------------\")\n",
        "    for cls, count in zip(sorted_classes, sorted_counts):\n",
        "        label_name = labels_dict[cls] if labels_dict else cls\n",
        "        print(f\"Class {label_name}: {count} samples\")\n",
        "\n",
        "    # Plot bar chart\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(sorted_classes, sorted_counts, tick_label=[labels_dict[cls] if labels_dict else cls for cls in sorted_classes])\n",
        "    plt.xlabel(\"Class\")\n",
        "    plt.ylabel(\"Number of Samples\")\n",
        "    plt.title(\"Class Distribution in Training Dataset\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_class_distribution(X_train, y_train, labels_dict=unique_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffOzuenalE9H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def save_processed_data(X_train, y_train, X_val, y_val, folder_path=\"finalDataset_partial\"):\n",
        "    \"\"\"\n",
        "    Saves processed training and validation datasets into a specified folder.\n",
        "\n",
        "    Parameters:\n",
        "        X_train (numpy array): Training data.\n",
        "        y_train (numpy array): Training labels.\n",
        "        X_val (numpy array): Validation data.\n",
        "        y_val (numpy array): Validation labels.\n",
        "        folder_path (str): Folder path to save the data.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Create the folder if it doesn't exist\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "    # Save the datasets\n",
        "    np.save(os.path.join(folder_path, \"X_train.npy\"), X_train)\n",
        "    np.save(os.path.join(folder_path, \"y_train.npy\"), y_train)\n",
        "    np.save(os.path.join(folder_path, \"X_val.npy\"), X_val)\n",
        "    np.save(os.path.join(folder_path, \"y_val.npy\"), y_val)\n",
        "\n",
        "    print(f\"Processed data saved in folder: {folder_path}\")\n",
        "\n",
        "save_processed_data(X_train, y_train, X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDZkhPwNlLq6"
      },
      "outputs": [],
      "source": [
        "def load_processed_data(folder_path=\"processed_dataMax\"):\n",
        "    \"\"\"\n",
        "    Loads processed training and validation datasets from a specified folder.\n",
        "\n",
        "    Parameters:\n",
        "        folder_path (str): Folder path from which to load the data.\n",
        "\n",
        "    Returns:\n",
        "        X_train, y_train, X_val, y_val (numpy arrays): Loaded datasets.\n",
        "    \"\"\"\n",
        "    # Load the datasets\n",
        "    X_train = np.load(os.path.join(folder_path, \"X_train.npy\"))\n",
        "    y_train = np.load(os.path.join(folder_path, \"y_train.npy\"))\n",
        "    X_val = np.load(os.path.join(folder_path, \"X_val.npy\"))\n",
        "    y_val = np.load(os.path.join(folder_path, \"y_val.npy\"))\n",
        "\n",
        "    print(f\"Processed data loaded from folder: {folder_path}\")\n",
        "    return X_train, y_train, X_val, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Is5XCQ8KrMyG"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_processed_data()\n",
        "\n",
        "print(\"Training Data Shape:\", X_train.shape)\n",
        "print(\"Training Label Shape:\", y_train.shape)\n",
        "print(\"Validation Data Shape:\", X_val.shape)\n",
        "print(\"Validation Label Shape:\", y_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFnInv6E8oM7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def show_grid_of_class_samples(X, y, target_class):\n",
        "    \"\"\"\n",
        "    Displays a 10x10 grid of samples from the specified class in the dataset, with larger images and reduced clutter.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy array): Array of images (num_samples, height, width, channels).\n",
        "        y (numpy array): Array of labels (num_samples,).\n",
        "        target_class (int): The class to display in the grid.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Filter images that belong to the specified class\n",
        "    class_indices = np.where(y == target_class)[0]\n",
        "    class_images = X[class_indices]\n",
        "\n",
        "    # Ensure there are at least 100 samples for the grid\n",
        "    if len(class_images) < 100:\n",
        "        print(f\"Not enough samples for class {target_class}. Only {len(class_images)} available.\")\n",
        "        return\n",
        "\n",
        "    # Display the 10x10 grid of the first 100 samples from the specified class\n",
        "    plt.figure(figsize=(15, 15))  # Increase figure size for larger images\n",
        "    for i in range(100):\n",
        "        plt.subplot(10, 10, i + 1)\n",
        "        plt.imshow(class_images[i].astype('uint8'))\n",
        "        plt.axis(\"off\")  # Remove axes for a cleaner look\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.1, hspace=0.1)  # Reduce spacing between images\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "# Assuming X_train and y_train are your dataset and labels\n",
        "target_class = 0  # Replace with the class you want to display\n",
        "show_grid_of_class_samples(X_train, y_train, target_class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivYv4euGesLU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers as tfkl\n",
        "\n",
        "def perform_cutmix_augmix(X, y, class_label, beta=0.5, augmix_alpha=1.0):\n",
        "    \"\"\"\n",
        "    Applies CutMix between two randomly selected images of the same class, then applies AugMix to the entire image.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy array): Array of images (num_samples, height, width, channels).\n",
        "        y (numpy array): Array of labels (num_samples,).\n",
        "        class_label (int): The label of the class to apply CutMix and AugMix on.\n",
        "        beta (float): Parameter for the Beta distribution. Controls the size of the CutMix patch.\n",
        "        augmix_alpha (float): Parameter for blending the original and augmented images.\n",
        "\n",
        "    Returns:\n",
        "        final_image (numpy array): The resulting image after CutMix and AugMix.\n",
        "        class_label (int): The label of the selected class (single class).\n",
        "    \"\"\"\n",
        "    # Filter indices of images that belong to the specified class\n",
        "    class_indices = np.where(y == class_label)[0]\n",
        "\n",
        "    if len(class_indices) < 2:\n",
        "        raise ValueError(f\"Not enough samples for class {class_label} to apply CutMix.\")\n",
        "\n",
        "    # Randomly select two different images from the same class for CutMix\n",
        "    indices = np.random.choice(class_indices, 2, replace=False)\n",
        "    img1, img2 = X[indices[0]], X[indices[1]]\n",
        "\n",
        "    # Sample lambda from a Beta distribution for CutMix\n",
        "    lam = max(0.1,0.4)\n",
        "    H, W, _ = img1.shape\n",
        "\n",
        "    # Determine the CutMix patch size and position\n",
        "    cut_w = int(W * np.sqrt(1 - lam))\n",
        "    cut_h = int(H * np.sqrt(1 - lam))\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    # Calculate the bounding box for the CutMix patch\n",
        "    x1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    x2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    y1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    y2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    # Create the CutMix image\n",
        "    cutmix_image = img1.copy()\n",
        "    cutmix_image[y1:y2, x1:x2, :] = img2[y1:y2, x1:x2, :]\n",
        "\n",
        "    # Define AugMix augmentation pipeline\n",
        "    augmentation_pipeline = tf.keras.Sequential([\n",
        "        tfkl.RandomRotation((0.3,0.9), fill_mode='nearest'),\n",
        "    ])\n",
        "\n",
        "    # Apply AugMix to the entire CutMix image\n",
        "    aug_image = augmentation_pipeline(tf.expand_dims(cutmix_image, axis=0), training=True)\n",
        "    aug_image = tf.squeeze(aug_image).numpy()\n",
        "\n",
        "    # Blend AugMix result with the CutMix image\n",
        "    lam_aug = np.random.beta(augmix_alpha, augmix_alpha)\n",
        "    final_image = lam_aug * cutmix_image + (1 - lam_aug) * aug_image\n",
        "\n",
        "    # Clip values to valid range and convert to uint8\n",
        "    final_image = np.clip(final_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return final_image, class_label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7uR7zi5eUD0"
      },
      "outputs": [],
      "source": [
        "def augment_and_add_to_training(X_train, y_train, samples_per_class, beta=0.5, augmix_alpha=1.0):\n",
        "    \"\"\"\n",
        "    Generates augmented samples for each class and adds them to the existing training dataset.\n",
        "\n",
        "    Parameters:\n",
        "        X_train (numpy array): Array of training images (num_samples, height, width, channels).\n",
        "        y_train (numpy array): Array of training labels (num_samples,).\n",
        "        samples_per_class (dict): Dictionary specifying the number of augmented samples to generate for each class.\n",
        "                                  Example: {0: 100, 1: 50, ...}\n",
        "        beta (float): Parameter for the Beta distribution. Controls the size of the CutMix patch.\n",
        "        augmix_alpha (float): Parameter for blending the original and augmented images.\n",
        "\n",
        "    Returns:\n",
        "        X_train (numpy array): Updated training images including augmented samples.\n",
        "        y_train (numpy array): Updated training labels including augmented samples.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    for class_label, num_samples in samples_per_class.items():\n",
        "        print(f\"Generating {num_samples} augmented samples for class {class_label}...\")\n",
        "        augmented_X = []\n",
        "        augmented_y = []\n",
        "        for _ in range(num_samples):\n",
        "            try:\n",
        "                aug_image, aug_label = perform_cutmix_augmix(X_train, y_train, class_label, beta, augmix_alpha)\n",
        "                augmented_X.append(aug_image)\n",
        "                augmented_y.append(aug_label)\n",
        "            except ValueError as e:\n",
        "                print(f\"Skipping class {class_label}: {e}\")\n",
        "                break\n",
        "        X_train = np.concatenate([X_train, np.array(augmented_X)],axis=0)\n",
        "        y_train = np.concatenate([y_train.flatten(), np.array(augmented_y)],axis=0)\n",
        "\n",
        "    # Convert augmented data to numpy arrays\n",
        "    augmented_X = np.array(augmented_X)\n",
        "    augmented_y = np.array(augmented_y)\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"New training set size: {X_train.shape[0]} samples.\")\n",
        "    return X_train, y_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ThJsMTje1g0"
      },
      "outputs": [],
      "source": [
        "# Define the number of samples to generate for each class\n",
        "\n",
        "'''\n",
        "Class Basophil: 765 samples\n",
        "Class Eosinophil: 1961 samples\n",
        "Class Erythroblast: 976 samples\n",
        "Class Immature granulocytes: 1820 samples\n",
        "Class Lymphocyte: 764 samples\n",
        "Class Monocyte: 893 samples\n",
        "Class Neutrophil: 2097 samples\n",
        "Class Platelet: 1479 samples\n",
        "'''\n",
        "\n",
        "#3147\n",
        "samples_per_class = {\n",
        "    0:2382,\n",
        "    1:1186,\n",
        "    2:2171,\n",
        "    3:1327,\n",
        "    4:2383,\n",
        "    5:2254,\n",
        "    6:1050,\n",
        "    7:1668,\n",
        "}\n",
        "\n",
        "# Assuming X_train and y_train are your dataset\n",
        "X_train, y_train = augment_and_add_to_training(X_train, y_train, samples_per_class, beta=0.5, augmix_alpha=0.5)\n",
        "\n",
        "# Check the shapes of the updated dataset\n",
        "print(\"Updated X_train shape:\", X_train.shape)\n",
        "print(\"Updated y_train shape:\", y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2sm5iYzUY6C"
      },
      "outputs": [],
      "source": [
        "# Define the AugMix layer\n",
        "augmix_layer = keras_cv.layers.AugMix(\n",
        "    value_range=(0, 255),  # Set the value range of your images\n",
        "    severity=1.0,         # Increase the severity of augmentations\n",
        "    num_chains=3,         # Number of augmentation chains to combine\n",
        "    chain_depth=(1, 3),   # Range for the number of augmentations per chain\n",
        "    alpha=1.0,            # Strength of mixing the chains\n",
        "    seed=42\n",
        "    # Optional random seed for reproducibility\n",
        ")\n",
        "\n",
        "aug = keras_cv.layers.RandAugment(\n",
        "    value_range=(0, 255),\n",
        "    augmentations_per_image=3,\n",
        "    magnitude=0.5,\n",
        "    magnitude_stddev=0.15,\n",
        "    rate=0.9090909090909091,\n",
        "    geometric=True,\n",
        "    seed=seed,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_cutmix_augmix(X, y, class_label, beta=0.5, augmix_alpha=1.0):\n",
        "    \"\"\"\n",
        "    Applies CutMix and AugMix on images of the specified class and visualizes the original images and the resulting image.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy array): Array of images (num_samples, height, width, channels).\n",
        "        y (numpy array): Array of labels (num_samples,).\n",
        "        class_label (int): The label of the class to apply CutMix and AugMix on.\n",
        "        beta (float): Parameter for the Beta distribution. Controls the size of the CutMix patch.\n",
        "        augmix_alpha (float): Parameter for blending the original and augmented images.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Apply CutMix and AugMix\n",
        "    final_image, selected_class_label = perform_cutmix_augmix(X, y, class_label, beta, augmix_alpha)\n",
        "\n",
        "    # Filter indices of images that belong to the specified class\n",
        "    class_indices = np.where(y == class_label)[0]\n",
        "    indices = np.random.choice(class_indices, 2, replace=False)\n",
        "    img1, img2 = X[indices[0]], X[indices[1]]\n",
        "\n",
        "    # Plot the original images and the final result\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    axes[0].imshow(img1.astype(np.uint8))\n",
        "    axes[0].set_title(f\"Image 1 (Class {class_label})\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(img2.astype(np.uint8))\n",
        "    axes[1].set_title(f\"Image 2 (Class {class_label})\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    axes[2].imshow(final_image.astype(np.uint8))\n",
        "    axes[2].set_title(\"CutMix + AugMix Result\")\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "visualize_cutmix_augmix(X_train, y_train, 7, beta=0.5, augmix_alpha=1.0)"
      ],
      "metadata": {
        "id": "wp5wBoCX52VR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}