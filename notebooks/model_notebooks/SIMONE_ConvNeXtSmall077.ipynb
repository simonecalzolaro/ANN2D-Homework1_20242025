{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9945297,"sourceType":"datasetVersion","datasetId":6115395}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set seed for reproducibility\nseed = 42\n\n# Import necessary libraries\nimport os\nimport json\nimport random\n# Set environment variables before importing modules\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n\n# Suppress warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# Import necessary modules\nimport logging\nimport random\nimport numpy as np\n\n# Set seeds for random number generators in NumPy and Python\nnp.random.seed(seed)\nrandom.seed(seed)\n\n\nimport tensorflow as tf\n#from tensorflow import keras as tfk\nimport keras as tfk       #notice how I'm importing keras and not tensorflow.keras\nfrom keras.layers import Input, Dense, Dropout, Lambda\n#from tensorflow.keras.layers import Input, Dense, Dropout, Lambda\nfrom keras import layers as tfkl\nimport keras_cv\n\n\nprint(f\"Tensorflow version -> {tf.__version__}\")\nprint(f\"Keras version -> {tfk.__version__}\")\n# Set seed for TensorFlow\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)\n\n# Reduce TensorFlow verbosity\ntf.autograph.set_verbosity(0)\ntf.get_logger().setLevel(logging.ERROR)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\n# Print TensorFlow version\nprint(tf.__version__)\n\n# Import other libraries\nimport requests\nfrom io import BytesIO\nimport cv2\nfrom PIL import Image\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\n\n# Configure plot display settings\nsns.set(font_scale=1.4)\nsns.set_style('white')\nplt.rc('font', size=14)\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:22:46.302482Z","iopub.execute_input":"2024-11-19T15:22:46.302742Z","iopub.status.idle":"2024-11-19T15:22:46.332709Z","shell.execute_reply.started":"2024-11-19T15:22:46.302718Z","shell.execute_reply":"2024-11-19T15:22:46.331753Z"}},"outputs":[{"name":"stdout","text":"Tensorflow version -> 2.16.1\nKeras version -> 3.3.3\n2.16.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"X_train = np.load(\"/kaggle/input/datasetmax/processed_dataMax/X_train.npy\")\ny_train = np.load(\"/kaggle/input/datasetmax/processed_dataMax/y_train.npy\")\nX_val = np.load(\"/kaggle/input/datasetmax/processed_dataMax/X_val.npy\")\ny_val = np.load(\"/kaggle/input/datasetmax/processed_dataMax/y_val.npy\")\n\nindices = np.arange(X_train.shape[0])  # Create an array of indices\nnp.random.shuffle(indices)  # Shuffle the indices\n\n# Apply the shuffled indices to both X_train and y_train\nX_train = X_train[indices]\ny_train = y_train[indices]\n\nprint(\"Train shapes: \",X_train.shape,\" \",y_train.shape)\nprint(\"Validation shapes: \",X_val.shape,\" \",y_val.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:22:52.678957Z","iopub.execute_input":"2024-11-19T15:22:52.679325Z","iopub.status.idle":"2024-11-19T15:23:22.235442Z","shell.execute_reply.started":"2024-11-19T15:22:52.679287Z","shell.execute_reply":"2024-11-19T15:23:22.234497Z"}},"outputs":[{"name":"stdout","text":"Train shapes:  (39687, 96, 96, 3)   (39687,)\nValidation shapes:  (1196, 96, 96, 3)   (1196, 1)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def save_model(code, model, history, folder_name):\n\n    \"\"\"\n\n    Salva il modello e i parametri in una cartella specificata.\n\n\n\n    Args:\n\n    - model: il modello da salvare\n\n    - params: dizionario contenente i parametri da salvare (es. learning rate, batch size, etc.)\n\n    - folder_name: nome della cartella di destinazione (default: 'model_folder')\n\n    \"\"\"\n\n    # Crea la cartella se non esiste\n\n    os.makedirs(folder_name, exist_ok=True)\n\n\n\n    if code == 0:\n\n          model_save_path = os.path.join(folder_name, 'weightsTL.keras')\n\n          model.save(model_save_path)\n\n          print(f\"ModelTL saved at: {model_save_path}\")\n\n    else:\n\n         model_save_path = os.path.join(folder_name, 'weights.keras')\n\n         model.save(model_save_path)\n\n         print(f\"Model saved at: {model_save_path}\")\n\n\n\n    # Salvataggio della history in un file JSON\n\n    if code == 0:\n\n       history_save_path = os.path.join(folder_name, 'historyTL.json')\n\n       with open(history_save_path, 'w') as f:\n\n           json.dump(history, f, indent=4)\n\n       print(f\"HistoryTL saved at: {history_save_path}\")\n\n    else:\n\n      history_save_path = os.path.join(folder_name, 'history.json')\n\n      with open(history_save_path, 'w') as f:\n\n           json.dump(history, f, indent=4)\n\n      print(f\"History saved at: {history_save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:23:30.218496Z","iopub.execute_input":"2024-11-19T15:23:30.219205Z","iopub.status.idle":"2024-11-19T15:23:30.226208Z","shell.execute_reply.started":"2024-11-19T15:23:30.219174Z","shell.execute_reply":"2024-11-19T15:23:30.225303Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Define a mapping of labels to their corresponding cell type names\nlabels = {\n    0: 'Basophil',\n    1: 'Eosinophil',\n    2: 'Erythroblast',\n    3: 'Immature granulocytes',\n    4: 'Lymphocyte',\n    5: 'Monocyte',\n    6: 'Neutrophil',\n    7: 'Platelet'\n}\n# Save unique labels\nunique_labels = list(labels.values())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:23:34.982126Z","iopub.execute_input":"2024-11-19T15:23:34.983011Z","iopub.status.idle":"2024-11-19T15:23:34.987528Z","shell.execute_reply.started":"2024-11-19T15:23:34.982973Z","shell.execute_reply":"2024-11-19T15:23:34.986620Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sklearn.utils import class_weight\n\n# Calcola i pesi delle classi\nclass_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train.flatten()), y=y_train.flatten())\nclass_weight_dict = dict(enumerate(class_weights))\n\nprint(\"Class weights:\", class_weight_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:23:39.637833Z","iopub.execute_input":"2024-11-19T15:23:39.638627Z","iopub.status.idle":"2024-11-19T15:23:39.663415Z","shell.execute_reply.started":"2024-11-19T15:23:39.638592Z","shell.execute_reply":"2024-11-19T15:23:39.662556Z"}},"outputs":[{"name":"stdout","text":"Class weights: {0: 1.1264475476839237, 1: 0.8432559918408975, 2: 1.1264475476839237, 3: 0.9085851648351648, 4: 1.1264475476839237, 5: 1.1264475476839237, 6: 0.7885670004768717, 7: 1.1180696416497633}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Convert class labels to categorical format for training, validation, and test sets\ny_train = tfk.utils.to_categorical(y_train, num_classes=len(unique_labels))\ny_val = tfk.utils.to_categorical(y_val, num_classes=len(unique_labels))\n\n\n\n# Print shapes of the datasets\nprint(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\nprint(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:23:42.215845Z","iopub.execute_input":"2024-11-19T15:23:42.216183Z","iopub.status.idle":"2024-11-19T15:23:42.222842Z","shell.execute_reply.started":"2024-11-19T15:23:42.216152Z","shell.execute_reply":"2024-11-19T15:23:42.222022Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (39687, 96, 96, 3), y_train shape: (39687, 8)\nX_val shape: (1196, 96, 96, 3), y_val shape: (1196, 8)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Input shape for the model\ninput_shape = X_train.shape[1:]\n\n# Output shape for the model\noutput_shape = y_train.shape[-1]\n\nprint(\"Input Shape:\", input_shape)\nprint(\"Output Shape:\", output_shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:23:45.200483Z","iopub.execute_input":"2024-11-19T15:23:45.200826Z","iopub.status.idle":"2024-11-19T15:23:45.206199Z","shell.execute_reply.started":"2024-11-19T15:23:45.200797Z","shell.execute_reply":"2024-11-19T15:23:45.205235Z"}},"outputs":[{"name":"stdout","text":"Input Shape: (96, 96, 3)\nOutput Shape: 8\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Batch size for training\nbatch_size = 128\n\n# Learning rate: step size for updating the model's weights\nlearning_rate = 1e-4\n\n\nl2_lambda = 1e-4\n\n# Augmentation: set an augmentation layer or not\naugmentation = True\n\n# Patience\npatience = 10\n\nfolder_name = \"ConvNeXtSmall_V3\"\n\n# Dropout\n\n#Name\nname = 'ConvNeXtSmall_V3'\n\n#Display the architecture\ndisplay = False\n\n# Print the defined parameters\nprint(\"Batch Size:\", batch_size)\nprint(\"Learning Rate:\", learning_rate)\nprint(\"Augmentation:\", augmentation)\nprint(\"Patience:\", patience)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:23:53.841912Z","iopub.execute_input":"2024-11-19T15:23:53.842249Z","iopub.status.idle":"2024-11-19T15:23:53.848289Z","shell.execute_reply.started":"2024-11-19T15:23:53.842219Z","shell.execute_reply":"2024-11-19T15:23:53.847323Z"}},"outputs":[{"name":"stdout","text":"Batch Size: 128\nLearning Rate: 0.0001\nAugmentation: True\nPatience: 10\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\n# Base model with stochastic depth\ninitializer = tfk.initializers.GlorotNormal(seed=seed)\nregulariser = tfk.regularizers.l2(l2_lambda)\n\ntl_model = tfk.applications.ConvNeXtSmall(\n    include_top=False,\n    include_preprocessing=True,  # Handles preprocessing internally\n    weights=\"imagenet\",\n    input_shape=input_shape,\n    pooling=\"avg\",\n)\ntl_model.trainable = False\n\n# Input preprocessing\ninputs = tfkl.Input(shape=(None, None, 3))  # Handle arbitrary input sizes\n\n\n\nx = tfkl.Resizing(96, 96)(inputs)\n\n\n# Feature extraction\nx = tl_model(x)\n\n# Stronger regularization in head\nx = tfkl.Dense(512,kernel_initializer= initializer)(x)\nx = tfkl.Activation('relu')(x)\nx = tfkl.Dropout(0.5)(x)\n\nx = tfkl.Dense(256,kernel_initializer= initializer)(x)\nx = tfkl.Activation('relu')(x)\nx = tfkl.Dropout(0.5)(x)\n\n# Output with label smoothing\noutputs = tfkl.Dense(\n    8,\n    activation='softmax',\n    kernel_initializer= initializer,\n    kernel_regularizer=regulariser\n)(x)\n\ntl_model = tfk.Model(inputs=inputs, outputs=outputs, name=name)\n\n# Cosine decay with warmup\n# Cosine decay schedule\nlr_schedule = tfk.optimizers.schedules.CosineDecayRestarts(\n    initial_learning_rate=learning_rate,\n    first_decay_steps=500,\n    t_mul=1.5,\n    m_mul=0.85,\n    alpha=0.05\n)\n\n\ntl_model.compile(\n    optimizer=tfk.optimizers.AdamW(learning_rate=lr_schedule,weight_decay=l2_lambda ),\n    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),\n    metrics=['accuracy']\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:23:58.051847Z","iopub.execute_input":"2024-11-19T15:23:58.052517Z","iopub.status.idle":"2024-11-19T15:24:05.464987Z","shell.execute_reply.started":"2024-11-19T15:23:58.052483Z","shell.execute_reply":"2024-11-19T15:24:05.464315Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_small_notop.h5\n\u001b[1m198551472/198551472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"tl_history = tl_model.fit(\n        X_train,\n        y_train,\n        batch_size=128,\n        validation_data=(X_val, y_val),\n        epochs=3,\n        class_weight=class_weight_dict,\n    ).history\n\n\n# Calculate and print the best validation accuracy achieved\nfinal_val_accuracy = round(max(tl_history['val_accuracy']) * 100, 2)\nprint(f'Final validation accuracy: {final_val_accuracy}%')\n\n# Save the trained model to a file, including final accuracy in the filename\nsave_model(0,tl_model, tl_history, folder_name)  #+ str(final_val_accuracy)\n\n# Free memory by deleting the model instance\n\ndel tl_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:24:08.618736Z","iopub.execute_input":"2024-11-19T15:24:08.619457Z","iopub.status.idle":"2024-11-19T15:26:32.826619Z","shell.execute_reply.started":"2024-11-19T15:24:08.619420Z","shell.execute_reply":"2024-11-19T15:26:32.825671Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1732029873.986634      70 service.cc:145] XLA service 0x7d4c5c097a30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1732029873.987392      70 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/311\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07:21\u001b[0m 25s/step - accuracy: 0.1328 - loss: 2.7662","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1732029883.664887      70 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 146ms/step - accuracy: 0.2247 - loss: 2.2748 - val_accuracy: 0.6329 - val_loss: 1.6305\nEpoch 2/3\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 100ms/step - accuracy: 0.3997 - loss: 1.8223 - val_accuracy: 0.6948 - val_loss: 1.4924\nEpoch 3/3\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 100ms/step - accuracy: 0.4834 - loss: 1.7027 - val_accuracy: 0.7567 - val_loss: 1.3617\nFinal validation accuracy: 75.67%\nModelTL saved at: ConvNeXtSmall_V3/weightsTL.keras\nHistoryTL saved at: ConvNeXtSmall_V3/historyTL.json\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"ft_model = tfk.models.load_model(folder_name+'/weightsTL.keras')\n# Display a summary of the model architecture\n#ft_model.summary(expand_nested=True,show_trainable=True)\n\n# Display model architecture with layer shapes and trainable parameters\n#tfk.utils.plot_model(ft_model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:26:34.737761Z","iopub.execute_input":"2024-11-19T15:26:34.738601Z","iopub.status.idle":"2024-11-19T15:26:56.299200Z","shell.execute_reply.started":"2024-11-19T15:26:34.738566Z","shell.execute_reply":"2024-11-19T15:26:56.298515Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Unfreeze only the last 20 layers of the ConvNeXt backbone\nconvnext_layers = [\n    layer for layer in ft_model.get_layer(\"convnext_small\").layers\n]\n\nprint(len(convnext_layers))\n\n# Freeze all layers initially\nfor layer in convnext_layers:\n    layer.trainable = False\n\n# Unfreeze the last 40 layers\nfor layer in convnext_layers[-40:]:\n    layer.trainable = True\n    #print(layer.name, type(layer).__name__, layer.trainable)\n\n#ft_model.summary(expand_nested=True,show_trainable=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:27:08.428983Z","iopub.execute_input":"2024-11-19T15:27:08.429615Z","iopub.status.idle":"2024-11-19T15:27:08.437071Z","shell.execute_reply.started":"2024-11-19T15:27:08.429582Z","shell.execute_reply":"2024-11-19T15:27:08.436115Z"}},"outputs":[{"name":"stdout","text":"260\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Cosine decay with warmup\n# Cosine decay schedule\nlr_schedule = tfk.optimizers.schedules.CosineDecayRestarts(\n    initial_learning_rate=learning_rate,\n    first_decay_steps=500,\n    t_mul=1.5,\n    m_mul=0.85,\n    alpha=0.05\n)\n\n\nft_model.compile(\n    optimizer=tfk.optimizers.AdamW(learning_rate=lr_schedule,weight_decay=l2_lambda ),\n    loss=tfk.losses.CategoricalCrossentropy(label_smoothing=0.2),\n    metrics=['accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:27:11.719585Z","iopub.execute_input":"2024-11-19T15:27:11.720328Z","iopub.status.idle":"2024-11-19T15:27:11.730629Z","shell.execute_reply.started":"2024-11-19T15:27:11.720292Z","shell.execute_reply":"2024-11-19T15:27:11.729904Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"ft_history = ft_model.fit(\n        X_train,\n        y_train,\n        batch_size=128,\n        validation_data=(X_val, y_val),\n        epochs=3000,\n        class_weight=class_weight_dict,\n        \n        callbacks = [\n            tfk.callbacks.EarlyStopping(\n                monitor='val_loss',\n                patience=10,\n                restore_best_weights=True\n            )\n        ]\n        \n    ).history\n\n# Calculate and print the final validation accuracy\nfinal_val_accuracy = round(max(ft_history['val_accuracy']) * 100, 2)\nprint(f'Final validation accuracy: {final_val_accuracy}%')\n\n# Save the trained model to a file, including final accuracy in the filename\nsave_model(1,ft_model, ft_history, folder_name)\n\n# Delete the model to free up resources\ndel ft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:27:15.209150Z","iopub.execute_input":"2024-11-19T15:27:15.209515Z","iopub.status.idle":"2024-11-19T15:57:18.596790Z","shell.execute_reply.started":"2024-11-19T15:27:15.209483Z","shell.execute_reply":"2024-11-19T15:57:18.595914Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3000\n\u001b[1m  1/311\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:13:25\u001b[0m 37s/step - accuracy: 0.4766 - loss: 1.6326","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1732030082.956063      71 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_transpose_fusion_140', 4 bytes spill stores, 4 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6428 - loss: 1.4719","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1732030133.295129      70 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_transpose_fusion_140', 4 bytes spill stores, 4 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 185ms/step - accuracy: 0.6430 - loss: 1.4716 - val_accuracy: 0.9181 - val_loss: 1.0184\nEpoch 2/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.7822 - loss: 1.2649 - val_accuracy: 0.9457 - val_loss: 0.9740\nEpoch 3/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.8255 - loss: 1.1971 - val_accuracy: 0.9599 - val_loss: 0.9384\nEpoch 4/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.8607 - loss: 1.1380 - val_accuracy: 0.9624 - val_loss: 0.9273\nEpoch 5/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.8709 - loss: 1.1206 - val_accuracy: 0.9682 - val_loss: 0.9095\nEpoch 6/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.8945 - loss: 1.0770 - val_accuracy: 0.9666 - val_loss: 0.8972\nEpoch 7/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9108 - loss: 1.0456 - val_accuracy: 0.9716 - val_loss: 0.8889\nEpoch 8/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9186 - loss: 1.0332 - val_accuracy: 0.9724 - val_loss: 0.8914\nEpoch 9/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9170 - loss: 1.0297 - val_accuracy: 0.9758 - val_loss: 0.8806\nEpoch 10/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9337 - loss: 1.0020 - val_accuracy: 0.9783 - val_loss: 0.8755\nEpoch 11/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9442 - loss: 0.9789 - val_accuracy: 0.9808 - val_loss: 0.8726\nEpoch 12/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9532 - loss: 0.9650 - val_accuracy: 0.9791 - val_loss: 0.8694\nEpoch 13/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9576 - loss: 0.9558 - val_accuracy: 0.9808 - val_loss: 0.8678\nEpoch 14/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9573 - loss: 0.9561 - val_accuracy: 0.9766 - val_loss: 0.8688\nEpoch 15/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9613 - loss: 0.9462 - val_accuracy: 0.9724 - val_loss: 0.8707\nEpoch 16/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9708 - loss: 0.9292 - val_accuracy: 0.9774 - val_loss: 0.8649\nEpoch 17/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9776 - loss: 0.9156 - val_accuracy: 0.9791 - val_loss: 0.8650\nEpoch 18/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9831 - loss: 0.9060 - val_accuracy: 0.9741 - val_loss: 0.8659\nEpoch 19/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9861 - loss: 0.8982 - val_accuracy: 0.9766 - val_loss: 0.8625\nEpoch 20/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9872 - loss: 0.8946 - val_accuracy: 0.9783 - val_loss: 0.8608\nEpoch 21/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9896 - loss: 0.8916 - val_accuracy: 0.9791 - val_loss: 0.8589\nEpoch 22/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9896 - loss: 0.8909 - val_accuracy: 0.9774 - val_loss: 0.8609\nEpoch 23/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9893 - loss: 0.8892 - val_accuracy: 0.9766 - val_loss: 0.8613\nEpoch 24/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9924 - loss: 0.8819 - val_accuracy: 0.9766 - val_loss: 0.8628\nEpoch 25/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9935 - loss: 0.8760 - val_accuracy: 0.9766 - val_loss: 0.8618\nEpoch 26/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 130ms/step - accuracy: 0.9953 - loss: 0.8697 - val_accuracy: 0.9758 - val_loss: 0.8645\nEpoch 27/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9964 - loss: 0.8657 - val_accuracy: 0.9741 - val_loss: 0.8629\nEpoch 28/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 130ms/step - accuracy: 0.9962 - loss: 0.8628 - val_accuracy: 0.9749 - val_loss: 0.8597\nEpoch 29/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 131ms/step - accuracy: 0.9967 - loss: 0.8601 - val_accuracy: 0.9741 - val_loss: 0.8582\nEpoch 30/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 130ms/step - accuracy: 0.9975 - loss: 0.8579 - val_accuracy: 0.9741 - val_loss: 0.8594\nEpoch 31/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 131ms/step - accuracy: 0.9981 - loss: 0.8567 - val_accuracy: 0.9758 - val_loss: 0.8562\nEpoch 32/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 131ms/step - accuracy: 0.9981 - loss: 0.8554 - val_accuracy: 0.9758 - val_loss: 0.8554\nEpoch 33/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 131ms/step - accuracy: 0.9981 - loss: 0.8545 - val_accuracy: 0.9758 - val_loss: 0.8551\nEpoch 34/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9981 - loss: 0.8547 - val_accuracy: 0.9749 - val_loss: 0.8627\nEpoch 35/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9979 - loss: 0.8558 - val_accuracy: 0.9774 - val_loss: 0.8573\nEpoch 36/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9983 - loss: 0.8530 - val_accuracy: 0.9774 - val_loss: 0.8574\nEpoch 37/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 130ms/step - accuracy: 0.9987 - loss: 0.8512 - val_accuracy: 0.9732 - val_loss: 0.8605\nEpoch 38/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9988 - loss: 0.8485 - val_accuracy: 0.9732 - val_loss: 0.8609\nEpoch 39/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9989 - loss: 0.8466 - val_accuracy: 0.9699 - val_loss: 0.8598\nEpoch 40/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 130ms/step - accuracy: 0.9991 - loss: 0.8449 - val_accuracy: 0.9774 - val_loss: 0.8578\nEpoch 41/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9992 - loss: 0.8438 - val_accuracy: 0.9749 - val_loss: 0.8588\nEpoch 42/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9992 - loss: 0.8427 - val_accuracy: 0.9749 - val_loss: 0.8579\nEpoch 43/3000\n\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.9996 - loss: 0.8414 - val_accuracy: 0.9741 - val_loss: 0.8562\nFinal validation accuracy: 98.08%\nModel saved at: ConvNeXtSmall_V3/weights.keras\nHistory saved at: ConvNeXtSmall_V3/history.json\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nmodel = tfk.models.load_model(folder_name+'/weights.keras')\npredictions = model.predict(X_val)\npredicted_classes = np.argmax(predictions, axis=1)\nprint(classification_report(np.argmax(y_val,axis=-1), predicted_classes))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}